defaults:
  - _self_
  - paths: default
  - hydra: default


# task name, determines output directory path

task_name: ???

# tags to help you identify your experiments
# you can overwrite this in experiment configs
# overwrite from command line with `python train.py tags="[first_tag, second_tag]"`
tags: []

seed: 10

base:
  img_size: 224
  device: cuda
  path_to_landmarks: <path_to_npys>
  path_to_rgb: <path_to_rgb>
  chars_ctc: "_ &'.@abcdefghijklmnopqrstuvwxyz" # no pad token needed for ctc, only blank + classes
  classes: ${len:${base.chars_ctc}}
  epochs: 1




datamodule:
  _target_: src.data.KP_RGB.dataset.JointDatasetDataModule
  img_size: ${base.img_size}
  test_df: <path_to_test_df>
  train_df: <path_to_train_df>

  path_to_landmarks: ${base.path_to_landmarks}
  path_to_rgb: ${base.path_to_rgb}

  batch_size: 4
  num_workers: 16
  horizontal_flip_prob: 0.5
  temporal_resample_prob: 0.8
  rotatation_prob: 0.5
  inference_args: <path_to_columns_name_json>
  symmetry_fp: <path_to_symmetry_csv>
  inds_to_filter: ["hand", "pose"]




model:
  _target_: src.models.KP_RGB.models.JointEncoders

  encoder_rgb:
    _target_: src.models.KP_RGB.models.TSM_Resnet_Encoder
    encoder: resnet34
    unidirection: True

  encoder_kp:
    _target_: src.models.KP_RGB.models.MLP_FE

    fe:
      _target_: src.models.KP_RGB.models.FeatureMapExtractorModel
      num_keypoints: 54
      out_dim: 144

    mlp:
      _target_: src.models.KP_RGB.models.MLP
      input_dim: 144
      hidden_dim: 512
      output_dim: 1024
      double_conv: True # True for chicagoFSWild, False for chicagoFSWildPlus

  reduction: sum
  decoder:
    _target_: src.utils.ctc_decoder.Decoder
    labels: ${base.chars_ctc}
    blank_index: 0

  decoder_net:
    _target_: src.models.KP_RGB.models.RNNHead
    input_dim: 1024
    hidden_dim: 1024
    num_layers: 2
    num_classes: ${base.classes}
    bidirectional: true
    return_outs: false

optimizer:
  _target_: torch.optim.AdamW
  lr: 0.0001
  _partial_: true


scheduler:
    _target_: torch.optim.lr_scheduler.MultiStepLR
    milestones: [20, 40]
    gamma: 0.1
    _partial_: True



trainer:
  _target_: src.models.KP_RGB.trainers.Trainer
  _partial_: true
  loss_fn:
    _target_: torch.nn.CTCLoss
    blank: 0
    zero_infinity: true
    reduction: sum
  device: ${base.device}
  val_every: 1
  path_to_save_weights: <path_to_save_weights>
  get_metric_train: true
  loss_scale: 1
  path_to_states: <path_to_states> # if want to retrain model
  resume_path: <path_to_resume_weights> # if want to continue training





test:
  tester:
    _target_: src.models.KP_RGB.tester.KP_RGBTester

  datamodule:
    _target_: src.data.KP_RGB.dataset.JointDatasetDataModule
    img_size: ${base.img_size}
    test_df: <path_to_test_df>
    train_df: <path_to_train_df>

    path_to_landmarks: ${base.path_to_landmarks}
    path_to_rgb: ${base.path_to_rgb}

    batch_size: 1
    num_workers: 16
    horizontal_flip_prob: 0.
    temporal_resample_prob: 0.
    rotatation_prob: 0.
    inference_args: <path_to_columns_name_json>
    symmetry_fp: <path_to_symmetry_csv>
    inds_to_filter: ["hand", "pose"]


  device: "cuda"
  weights: <weights_to_test>
  split: "test"
